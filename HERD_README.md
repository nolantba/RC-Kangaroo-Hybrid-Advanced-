# SOTA++ Herds Integration Guide

## ğŸ“ Files Created

1. **HerdConfig.h** - Configuration for herd parameters
2. **GpuHerdManager.h** - Manager class for herd coordination  
3. **GpuHerdKernels.cu** - CUDA kernels with herd support

## ğŸ”§ Integration Steps

### Step 1: Add to Makefile

```makefile
# Add herd object files
OBJS += GpuHerdManager.o

# Compilation rules
GpuHerdManager.o: GpuHerdManager.cpp GpuHerdManager.h HerdConfig.h
	$(CXX) $(CXXFLAGS) -c GpuHerdManager.cpp

# Add to CUDA compilation
GpuHerdKernels.o: GpuHerdKernels.cu
	$(NVCC) $(NVCCFLAGS) -c GpuHerdKernels.cu
```

### Step 2: Modify GpuKang.h

```cpp
#include "GpuHerdManager.h"

class GpuKang {
private:
    // Add these members
    bool use_herds_;
    std::vector<GpuHerdManager*> herd_managers_;
    
public:
    void SetUseHerds(bool enable, int range_bits) {
        // Only use herds for puzzles 100+
        use_herds_ = enable && (range_bits >= 100);
    }
};
```

### Step 3: Modify GpuKang.cpp Initialization

```cpp
void GpuKang::Initialize(/* your params */, int range_bits) {
    // Decide if herds should be used
    SetUseHerds(true, range_bits);
    
    if (use_herds_) {
        printf("Enabling SOTA++ herds (puzzle %d bits)\n", range_bits);
        
        // Create herd configuration
        HerdConfig config = HerdConfig::forPuzzleSize(range_bits);
        
        // Create herd manager for each GPU
        for (int i = 0; i < gpuCount; i++) {
            GpuHerdManager* mgr = new GpuHerdManager(i, config);
            mgr->Initialize(range_bits);
            herd_managers_.push_back(mgr);
        }
    } else {
        printf("Using unified kangaroo pool\n");
        // Your existing initialization
    }
}
```

### Step 4: Modify Kernel Launch

```cpp
void GpuKang::Run() {
    if (use_herds_) {
        // Launch herd kernels
        for (auto* mgr : herd_managers_) {
            launchHerdKernels(
                mgr->GetMemory(),
                d_kangaroo_x,  // Your existing GPU arrays
                d_kangaroo_y,
                d_kangaroo_dist,
                10000  // iterations
            );
        }
        
        // Periodically print stats
        static int stats_counter = 0;
        if (++stats_counter % 1000 == 0) {
            for (auto* mgr : herd_managers_) {
                mgr->PrintHerdStats();
            }
        }
    } else {
        // Your existing kernel launch
        // kangarooKernel<<<blocks, threads>>>(...);
    }
}
```

### Step 5: Add Command Line Option

```cpp
// In RCKangaroo.cpp
bool use_herds = false;

// Parse args
if (strcmp(argv[i], "-herds") == 0) {
    use_herds = true;
    printf("SOTA++ herds enabled\n");
}

// Pass to GpuKang
gpuKang->SetUseHerds(use_herds, rangeBits);
```

## ğŸ§ª Testing

### Test 1: Small Puzzle (Should NOT use herds)
```bash
./rckangaroo -dp 14 -range 75 \
  -start 40000000000000000 \
  -pubkey 020ecdb6359d41d2fd37628c718dda9be30e65801a88d5a5cc8a81b77bfeba3f5a
  
# Should print: "Using unified kangaroo pool"
# Expected: ~30 seconds
```

### Test 2: Medium Puzzle (SHOULD use herds)
```bash
./rckangaroo -herds -dp 14 -range 90 \
  -start 200000000000000000000000 \
  -pubkey <pubkey>
  
# Should print: "Enabling SOTA++ herds (puzzle 90 bits)"
# Expected: 28-32 minutes (vs 40 min baseline)
# Target: >20% improvement
```

### Test 3: Large Puzzle (Maximum herds)
```bash
./rckangaroo -herds -dp 16 -range 100 \
  -start 8000000000000000000000000 \
  -pubkey <pubkey>
  
# Should use 16 herds per GPU
# Expected: 9-10 hours (vs 12.8 hours baseline)
# Target: >25% improvement
```

## ğŸ“Š Expected Performance

| Puzzle | Baseline | With Herds | Improvement |
|--------|----------|------------|-------------|
| 75 | 30s | 30s | 0% (too fast) |
| 90 | 40m | 28-32m | +20-25% |
| 100 | 12.8h | 9h | +30% |
| 110 | 8.5d | 6d | +30% |
| 120 | 136d | 95d | +30% |

## ğŸ› Troubleshooting

**Problem: "Using unified pool" when you want herds**
- Solution: Puzzle must be â‰¥100 bits OR use `-herds` flag

**Problem: Slower performance with herds**
- Solution: Disable for puzzles <100 bits (overhead too high)

**Problem: Out of memory**
- Solution: Reduce `herds_per_gpu` in HerdConfig (8 â†’ 4)

**Problem: CUDA errors**
- Solution: Check SM architecture in Makefile matches your GPU

## ğŸ¯ Configuration Tuning

Edit HerdConfig.h presets:

```cpp
// For your 3x RTX 3060 setup
static HerdConfig forMediumPuzzles() {
    HerdConfig cfg;
    cfg.herds_per_gpu = 8;      // Optimal for RTX 3060
    cfg.kangaroos_per_herd = 256;
    cfg.adaptive_jumps = true;
    cfg.dp_bits = 14;           // Adjust per puzzle
    return cfg;
}
```

## ğŸ“ˆ Monitoring

Watch herd stats in real-time:

```
[GPU 0] Herd Statistics:
Herd | Ops (M) | DPs Found | Rate (MK/s)
-----+---------+-----------+------------
   0 |   245.3 |     12847 |    1205.32
   1 |   248.1 |     13021 |    1219.47
   2 |   242.7 |     12654 |    1192.18
   3 |   246.9 |     12935 |    1213.76
   4 |   244.2 |     12782 |    1199.54
   5 |   247.5 |     12998 |    1216.23
   6 |   243.8 |     12718 |    1197.91
   7 |   245.6 |     12859 |    1206.45
```

All herds should have similar rates. If one herd is <80% of average, rebalancing kicks in.

## âœ… Success Criteria

- [ ] Builds without errors
- [ ] Small puzzles (<100 bits) use unified pool
- [ ] Large puzzles (â‰¥100 bits) use herds automatically
- [ ] Herd stats show balanced performance
- [ ] >20% speedup on Puzzle 90
- [ ] >25% speedup on Puzzle 110+

## ğŸš€ Next Steps

Once herds are working:

1. **Benchmark thoroughly** - Test Puzzles 90, 100, 110
2. **Tune configuration** - Optimize herds_per_gpu for your GPUs
3. **Profile memory** - Ensure no bottlenecks
4. **Document results** - Share with community!

## ğŸ’¡ Notes

- Herds add ~5-10% memory overhead
- Performance gains increase with puzzle size
- Adaptive features kick in after 10M+ operations
- Works with multi-GPU setups (each GPU gets own herds)

Good luck! ğŸ¯
